---
title: "Biomarkers of ASD"
subtitle: "If you want a subtitle put it here"
author: "Andrew Guerra, Pratyush Rallapally"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

Use this as a template. Keep the headers and remove all other text. In all, your report can be quite short. When it is complete, render and then push changes to your team repository.

```{r, message=FALSE}
# load any other packages and read data here
library(tidyverse)
library(here)
library(readr)
library(knitr)
library(dplyr)
raw.biomarkers <- read_csv(here("data", "biomarker-raw.csv"))

```

## Abstract

Write a brief one-paragraph abstract that describes the contents of your write-up.

## Dataset

The dataset originates from Hewitson et al. (2021), Blood biomarker discovery for autism spectrum disorder. The data were obtained from serum samples of 154 male children aged from 18 months to 8 years, including 76 boys diagnosed with autism spectrum disorder (ASD) and 78 typically developing (TD) controls. All participants were recruited through The Johnson Center for Child Health and Development in Austin, TX, and ASD diagnoses were confirmed via the Autism Diagnostic Observation Schedule (ADOS) and Autism Diagnostic Interview-Revised (ADI-R) under DSM-5 criteria. TD children were screened with the Adaptive Behavior Assessment System (ABAS-II) to rule out developmental concerns.

Blood samples were collected after participants fasted, then processed under controlled lab conditions. Protein levels were measured using the SomaLogic SOMAScan platform, which originally captured 1,317 proteins per sample. After running quality control checks, 1,125 proteins were kept for analysis.

## Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

## Findings

Summarize your findings here. I've included some subheaders in a way that seems natural to me; you can structure this section however you like.

### Impact of preprocessing and outliers

**What do you imagine is the reason for log-transforming the protein levels in biomarker-raw.csv?**

Before protein levels are measured, a log-transformation is applied. The protein levels in biomarker-raw.csv are logarithmically transformed to better capture small variations in biomarker level expression. When working with microscopic data such as protein levels, the range of values is often dramatic. As a result, data can often be accentuated more or less and make overall trends harder to detect. To control for this, we can apply a log-transformation to standardize our data range.

To verify this, we can sample from 5 proteins in the dataset and see their respective distributions.

```{r, out.width='80%', fig.align='center'}
set.seed(10302025)
# Change Headers to Protein Acronyms
raw.biomarkers1 <- raw.biomarkers
colnames(raw.biomarkers1) <- raw.biomarkers1[1,]
raw.data <- raw.biomarkers1[-1,]
sample.proteins <- sample(colnames(raw.data), 5)
# RS of n=4 data
cat('Our proteins sampled are: ', sample.proteins)

# Checking distributions
long.data <- raw.data %>%
  select(all_of(sample.proteins)) %>%
  pivot_longer(cols = everything(), names_to = "Protein", values_to = "Value") %>%
  mutate(Value = as.numeric(Value))

# Histogram
long.data %>% 
  drop_na() %>% 
ggplot(aes(x = Value)) +
  geom_histogram(color = "white", fill = "black", bins = 30) +
  facet_wrap(~ Protein, scales = "free_x") +
  labs(
    title = "Distributions of Selected Protein Biomarkers",
    x = "Protein Level",
    y = "Frequency"
  ) +
  theme_minimal()

```

After plotting the histograms of our sampled proteins, we see that they most (except Apo E4) exhibit notable skewness and are not normally distribution. Additionally, the range for these values is extremely wide. Next, we apply a log-transformation to help standardize our distribtutions.

```{r, fig.align='center', out.width='80%'}
set.seed(10302025)

long.data %>% 
  drop_na() %>% 
ggplot(aes(x = log(Value))) +
  geom_histogram(color = "white", fill = "black", bins = 30) +
  facet_wrap(~ Protein, scales = "free_x") +
  labs(
    title = "Distributions of Selected Protein Biomarkers",
    x = "Log-Transformed Protein Level",
    y = "Frequency"
  ) +
  theme_minimal()
```

After transforming our values, we see that the range is now much considerably smaller. Additionally, most of our proteins sampled follow a close-to-normal distribution. Interestingly, Coagulation Factor IX appears to have a median of about 8.8. This trend was not as apparent with applying a transformation. Thus, we have reason to suspect that this protein should be further investigated.

**Temporarily remove the outlier trimming from preprocessing and do some exploratory analysis of the outlying values. Are there specific subjects (not values) that seem to be outliers? If so, are outliers more frequent in one group of the other?**

Through our previous analyses, we see that the distribution of proteins are transformed to easily detect which have a non-normal relationship that can be investigated further. Shifting our focus, we aim to see whether subjects are outliers. That is, we aim to see whether there are subjects, portrayed as rows, that consist of outliers among multiple protein levels.

```{r fig.align='center', warning=FALSE, out.width='80%'}
proteins <- setdiff(names(raw.biomarkers), 
                    c("Group", "Target Full Name"))

z.scores <- raw.biomarkers %>% 
  mutate(across(all_of(proteins), ~scale(as.numeric(.x))))


outlier_summary <- z.scores %>% 
  mutate(across(all_of(proteins), ~abs(.x) > 3)) %>% 
  mutate(n_outliers = rowSums(across(all_of(proteins)), na.rm = TRUE)) %>% 
  filter(!is.na(Group) & Group != '') %>%
  group_by(Group) %>% 
  summarise(
    mean_outliers = mean(n_outliers, na.rm = TRUE),
    median_outliers = median(n_outliers, na.rm = TRUE),
    sd_outliers = sd(n_outliers, na.rm = TRUE),
    max_outliers = max(n_outliers, na.rm = TRUE),
    .groups = "drop"
  )

outlier_summary %>% kable(caption = 'Outlier Distribution Table', digits=2)
```

We created a table to see outlier trends by subject group. To do so, we standardized all 1,317 protein levels and counted values with an absolute value greater than 3 as an outlier. Based on our table, we see that ASD subjects had an average of about 17.04 outliers in protein levels while TD subjects had about 19.65. Additionally, the median outlier counters were nearly identical (9.5 for ASD and 10 for TD), indicating that the two groups have similar overall variation in protein measurements. However, the standard deviations (20.6 for ASD and 30.4 for TD) and maximum outlier counts (119 and 154, respectively) suggest that a few individual subjects in both groups exhibited unusually high numbers of outlying protein values. Overall, this does not suggest there being systematic differences between groups, rather it suggests there are few subjects in the data that have greater individual differences.

### Methodological variations

Task 3

### Simplified classifier

```{r, echo = FALSE, message=FALSE}
kable(bind_rows(metrics_yours, metrics_full), caption = "Training vs Full-Data Performance", digits = 3)
```

To identify a simpler panel while maintaining comparable classification accuracy, we applied a training-only feature selection procedure using the same combination of multiple testing and random forest methods as in the in-class analysis. By restricting selection to the training set, we avoided using any test data during feature selection, ensuring a more methodologically sound and generalizable panel. This approach yielded a panel of 4 proteins, compared with the larger 10-protein panel used in the in-class analysis, representing a reduction of roughly 60% in panel size. Despite this simplification, the panel achieved strong predictive performance (sensitivity 0.75, specificity 0.80, accuracy 0.774, AUC 0.871). Benchmarking against the in-class analysis (sensitivity 0.875, specificity 0.867, accuracy 0.871, AUC 0.925) shows that the slight reduction in performance is minor relative to the substantial gain in interpretability and efficiency, supporting the utility of the smaller panel. Using a smaller panel with fewer proteins has several practical benefits, including cheaper and faster assays in a lab setting, easier replication, and less risk of overfitting in predictions. Such a substantial decrease in the cost of resources justifies the minor accuracy loss.
